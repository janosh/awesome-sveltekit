/* eslint-disable no-console */
/* This file parses sites.yml, fetches GH metadata like contributors and star count for each
site, then writes the results to site/src/sites.yml. */

import dotenv from 'dotenv'
import fs from 'fs'
import yaml from 'js-yaml'
import { basename } from 'path'
import { performance } from 'perf_hooks'
import { root_dir, title_to_slug } from './index.js'

dotenv.config({ path: `${root_dir}/site/.env` })

const in_path = `${root_dir}/sites.yml`
const out_path = `${root_dir}/site/src/sites.yml`
const update_existing = process.argv[2] === `update-existing`

const sites = yaml.load(fs.readFileSync(in_path))

const old_sites = fs.existsSync(out_path)
  ? yaml.load(fs.readFileSync(out_path))
  : []

const this_file = basename(process.argv[1])
console.log(`Running ${this_file}...`)

const start = performance.now()

const old_slugs = old_sites.map((site) => site.slug)

const [seen_sites, skipped_sites, updated_sites] = [[], [], []]

if (!process.env.GH_TOKEN) {
  console.error(`GH_TOKEN environment variable is not set.`)
  process.exit(1)
}

const headers = {
  authorization: `token ${process.env.GH_TOKEN}`,
}

async function fetch_check(url) {
  const response = await fetch(url, { headers }).then((res) => res.json())
  if (response.message) throw new Error(response.message)
  return response
}

function normalizeUrl(url) {
  if (!url) return null
  if (url.startsWith(`http`)) return url.replace(`http://`, `https://`)
  return `https://${url}`
}

// Only update site/src/sites.js if a new site was added to sites.yml
// or repo star counts were last fetched more than a month ago.
for (const site of sites) {
  const slug = title_to_slug(site.title)

  if (seen_sites.includes(slug)) throw new Error(`Duplicate slug ${slug}`)
  else seen_sites.push(slug)

  site.slug = slug

  // add open-source tag for all sites with repo key
  if (site.repo && !site.tags.includes(`open source`)) {
    site.tags.push(`open source`)
    site.tags.sort((a, b) => a.localeCompare(b)) // sort tags alphabetically in place
  }

  // skip site if it doesn't have a repo key or if data was fetched for it before
  // and update_existing is false
  if (!site.repo || (old_slugs.includes(slug) && !update_existing)) {
    skipped_sites.push(slug)
    continue
  }

  // also skip site if repo key cannot be parsed into a user login and a repo name
  const repoHandle = site.repo.split(`github.com/`)[1]
  if (repoHandle.split(`/`).length !== 2) {
    console.error(`bad repo handle ${repoHandle}`)
    skipped_sites.push(slug)
    continue
  }

  // fetch star count
  try {
    const url = `https://api.github.com/repos/${repoHandle}`
    const repo = await fetch_check(url)
    site.repoStars = repo.stargazers_count
  } catch (error) {
    console.error(`Error fetching star count for ${site.title}:`, error)
  }

  // fetch most active contributors
  let contributors = await fetch_check(
    `https://api.github.com/repos/${repoHandle}/contributors`
  )

  // show at most 5 contributors and only those with more than 10 commits
  // and of type 'User' (to filter out bots) sorted by number of contributions
  contributors = contributors
    .filter((c) => c.contributions > 10 && c.type === `User`)
    .sort((c1, c2) => c2.contributions - c1.contributions)
    .slice(0, 5)

  contributors = await Promise.all(
    contributors.map(({ url }) => fetch(url, { headers }).then((r) => r.json()))
  )

  site.contributors = contributors.map(({ name, location, company, ...c }) => ({
    github: c.login,
    twitter: c.twitter_username,
    url: normalizeUrl(c.blog),
    avatar: c.avatar_url,
    name,
    location,
    company,
  }))

  updated_sites.push(slug)
}

const new_sites = sites.map((site) => {
  const old_site = old_sites.find((old) => old.slug === site.slug) ?? {}
  // retain fetched GitHub data from old_sites in case we didn't refetch
  // but overwrite with new data if we did
  for (const key of [`repoStars`, `contributors`]) {
    if (site[key] === undefined) site[key] = old_site[key]
  }
  return site
})

const wall_time = ((performance.now() - start) / 1000).toFixed(2)

const comment = `# auto-generated by ${this_file}\n`
fs.writeFileSync(out_path, comment + yaml.dump(new_sites))

console.log(
  `${this_file} took ${wall_time}s, updated ${updated_sites.length} sites,` +
    `skipped ${skipped_sites.length} sites\n`
)
